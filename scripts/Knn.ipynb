{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import surprise\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie-movie similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "1.0368534289524032\n",
      "{'k': 20, 'sim_options': {'name': 'msd', 'min_support': 2, 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "# path to dataset file\n",
    "file_path = \"../data/data_surprise.csv\"\n",
    "\n",
    "reader = Reader(line_format='user item rating', sep=',', skip_lines=1)\n",
    "\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "print('KNN')\n",
    "param_grid = {'k': [20],\n",
    "              'sim_options': {'name': ['msd'],\n",
    "                              'min_support': [2, 3, 4, 5],\n",
    "                              'user_based': [False]}\n",
    "              }\n",
    "                              \n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=2)\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.025355739615713"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.10)\n",
    "\n",
    "algo = gs.best_estimator['rmse']\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-user similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "1.0482214448779699\n",
      "{'k': 20, 'sim_options': {'name': 'msd', 'min_support': 2, 'user_based': True}}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "# path to dataset file\n",
    "file_path = \"../data/data_surprise.csv\"\n",
    "\n",
    "reader = Reader(line_format='user item rating', sep=',', skip_lines=1)\n",
    "\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "print('KNN')\n",
    "param_grid = {'k': [20, 40, 60],\n",
    "              'sim_options': {'name': ['msd'],\n",
    "                              'min_support': [2],\n",
    "                              'user_based': [True]}\n",
    "              }\n",
    "#'k': [20],\n",
    " #             'sim_options': {'name': ['msd', 'cosine', 'pearson'],\n",
    "  #                            'min_support': [2, 3, 4, 5],\n",
    "    #                          'user_based': [False]}\n",
    "     #         }\n",
    "                              \n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=2)\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0392122812950182"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.10)\n",
    "\n",
    "algo = gs.best_estimator['rmse']\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings that have to be predicted (items and users specified in sample_submission file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data_helpers import read_csv_sample\n",
    "\n",
    "INPUT_PATH = \"../data/sample_submission.csv\"\n",
    "ids = read_csv_sample(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write your craziest ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-b53775eec35b>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-b53775eec35b>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    create_csv_submission(ids_test, , OUTPUT_PATH)\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from data_helpers import create_csv_submission\n",
    "\n",
    "OUTPUT_PATH = \"../data/submission.csv\"\n",
    "create_csv_submission(ids, predictions, OUTPUT_PATH)\n",
    "print(\"File submission.csv ready to be submitted !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
