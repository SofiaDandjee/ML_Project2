{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import surprise\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_helpers import *\n",
    "\n",
    "#Load train and testset for the surprise models\n",
    "file_path = \"../data/data_surprise.csv\"\n",
    "trainset, testset = build_surprise_data(file_path)\n",
    "\n",
    "#Loads ratings to predict\n",
    "INPUT_PATH = \"../data/sample_submission.csv\"\n",
    "ids = read_csv_sample(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "#Load train and testset for the custom models\n",
    "train, test = split_data(load_data(\"../data/data_train.csv\"), p_test = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Baseline Movie\n",
      "   Training RMSE:  0.6241475383015472\n",
      "   Test RMSE:  0.9908785231084433\n",
      "kNN Baseline User\n",
      "   Training RMSE:  0.6641531098089988\n",
      "   Test RMSE:  0.9947164198559775\n",
      "SVD\n",
      "   Training RMSE:  0.9543999695353427\n",
      "   Test RMSE:  1.0019284327486202\n"
     ]
    }
   ],
   "source": [
    "Xtest = []\n",
    "Xids = []\n",
    "\n",
    "#Generate predictions with every method\n",
    "rmse, Xtest, Xids, preds_test_kbm, preds_ids_kbm = knn_baseline_movie(trainset, testset, ids, Xtest, Xids)\n",
    "rmse, Xtest, Xids, preds_test_kbu, preds_ids_kbu = knn_baseline_user(trainset, testset, ids, Xtest, Xids)\n",
    "rmse, Xtest, Xids, preds_test_svd, preds_ids_svd = svd(trainset, testset, ids, Xtest, Xids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj2_helpers import *\n",
    "def matrix_factorization_als2(train, test, ids, Xtest, Xids):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\n",
    "    Argument : train, the trainset\n",
    "               test, the testset\n",
    "               ids, unknown ratings\n",
    "               Xtest, predicted ratings for testset, to be used for final blending\n",
    "               Xids, predicted ratings for unknown ratings, to be used for final blending\n",
    "    \"\"\"\n",
    "    # define parameters\n",
    "    num_features = 20\n",
    "    lambda_user = 0.08\n",
    "    lambda_item = 0.1\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # get the number of non-zero ratings for each user and item\n",
    "    nnz_items_per_user, nnz_users_per_item = train.getnnz(axis=0), train.getnnz(axis=1)\n",
    "    \n",
    "    # group the indices by row or column index\n",
    "    nz_train, nz_item_userindices, nz_user_itemindices = build_index_groups(train)\n",
    "\n",
    "    # run ALS\n",
    "    print(\"start the ALS algorithm...\")\n",
    "    while change > stop_criterion:\n",
    "        # update user feature & item feature\n",
    "        user_features = update_user_feature(train, item_features, lambda_user, nnz_items_per_user, nz_user_itemindices)\n",
    "        item_features = update_item_feature(train, user_features, lambda_item, nnz_users_per_item, nz_item_userindices)\n",
    "\n",
    "        error = compute_error(train, user_features, item_features, nz_train)\n",
    "        \n",
    "        error_list.append(error)\n",
    "        change = np.fabs(error_list[-1] - error_list[-2])\n",
    "        \n",
    "    print(\"Training RMSE: {}.\".format(error))\n",
    "    # evaluate the test error\n",
    "    nnz_row, nnz_col = test.nonzero()\n",
    "    nnz_test = list(zip(nnz_row, nnz_col))\n",
    "    rmse = compute_error(test, user_features, item_features, nnz_test)\n",
    "    print(\"Test RMSE: {v}.\".format(v=rmse))\n",
    "    \n",
    "    predictions_matrix = user_features.T @ item_features\n",
    "    \n",
    "    #Predict unknown ratings\n",
    "    preds_ids = []\n",
    "    for i in range(len(ids[0])):\n",
    "        user = ids[0][i]\n",
    "        item = ids[1][i]\n",
    "        rating = round(predictions_matrix[item-1, user-1])\n",
    "        preds_ids.append(rating)\n",
    "\n",
    "    preds_ids = np.clip(preds_ids, 1, 5)\n",
    "    Xids.append(preds_ids)\n",
    "    \n",
    "    #Predict test ratings (known)\n",
    "    preds_test = compute_predictions(test, user_features, item_features, nnz_test)\n",
    "    preds_test = np.clip(preds_test, 1, 5)\n",
    "    Xtest.append(preds_test)\n",
    "    return rmse, Xtest, Xids, preds_test, preds_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start the ALS algorithm...\n"
     ]
    }
   ],
   "source": [
    "rmse, Xtest, Xids, preds_test_als, preds_ids_als = matrix_factorization_als2(train, test, ids, Xtest, Xids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, Xtest, Xids, preds_test_sgd, preds_ids_sgd = matrix_factorization_sgd(train, test, ids, Xtest, Xids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtest.shape) , (Xids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def blend(preds_test, preds_ids, testset):\n",
    "    \"\"\"\n",
    "    Linear regression that finds the optimal weights of each model\n",
    "    Argument : preds_test, predicted ratings for the known test set\n",
    "               preds_ids, predicted ratings for the unknown set\n",
    "               testset, the testset\n",
    "    Return : estimations, the final predictions\n",
    "             weights, coefficients associated to each model\n",
    "    \"\"\"\n",
    "    print('Blending')\n",
    "    \n",
    "    #Known ratings of testset\n",
    "    y_test = [rating for (_,_,rating) in testset]\n",
    "    \n",
    "    #Ridge Regression\n",
    "    linreg = Ridge(alpha=0.1, normalize=True)\n",
    "    \n",
    "    #Fit between predicted and know ratings of testset\n",
    "    linreg.fit(preds_test.T, y_test)\n",
    "    weights = linreg.coef_\n",
    "    \n",
    "    #Predict unknown ratings\n",
    "    predictions = np.clip(linreg.predict(preds_ids.T), 1, 5)\n",
    "    \n",
    "    print(weights, end='\\n\\n')\n",
    "    \n",
    "    #RMSE of regression\n",
    "    print('Test RMSE: %f' % calculate_rmse(y_test, linreg.predict(preds_test.T)))\n",
    "    \n",
    "    #Rounding-off predictions\n",
    "    estimations = np.zeros(len(predictions))\n",
    "    for j, pred in enumerate(predictions):\n",
    "        estimations[j] = round(pred)\n",
    "        \n",
    "    return estimations, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending\n",
      "[-1.8606002   0.50975616  0.99641749 -0.63334515  1.14645031  0.74535184\n",
      " -0.12279898  0.26282306  0.00458331]\n",
      "\n",
      "Test RMSE: 0.986415\n"
     ]
    }
   ],
   "source": [
    "#Blending\n",
    "predictions, weights = blend(np.array(Xtest), np.array(Xids), testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176952"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File submission.csv ready to be submitted !\n"
     ]
    }
   ],
   "source": [
    "from data_helpers import create_csv_submission\n",
    "\n",
    "OUTPUT_PATH = \"../data/submission.csv\"\n",
    "create_csv_submission(ids, predictions, OUTPUT_PATH)\n",
    "print(\"File submission.csv ready to be submitted !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
